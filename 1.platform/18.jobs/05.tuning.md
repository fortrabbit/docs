---
reviewed: 2025-07-01 13:33:05
title: Jobs tuning
naviTitle: Tuning
siblings: Jobs
navigation.excerpt: Extended knowledge on jobs
wip: true
---

## Logging

You can access the jobs. Both STDOUT and STDERR generated by any job are logged.

## Restart after code update

This happens automatically. Whenever you push a new code update via [git deployment](/3.dev/2.deployment/1.intro.md), jobs will be shutdown and started anew.

## Considerations

- The total (max) memory amount of all jobs should be below the memory limit of the plan.
- Exits of jobs should be looked into. Usually nonstop worker jobs should run continuously and not exist often.

The memory limit is for all jobs combined. Resources needed for each application can vary largely, depending on what each particular job is doing.

## Graceful shutdown

Say your job does really long running stuff or is very busy - meaning that it's likely that it is currently working when you push new code, which leads to a restart of the job. In this case, you might not want to abort (restart) it. The solution is to utilize Unix signal handling to write a shutdown handler. For this you can use the automatically available [PCNTL](http://php.net/manual/en/book.pcntl.php) extension.

The most simplistic PHP script for a job is a while loop:

```php
while (true) {
  do_something();
  sleep(5);
}
```

To make sure that `do_something()` is never aborted, you can extend the script like so:

```php
declare(ticks=1);

$shutdown = false;
pcntl_signal(SIGTERM, function($signo) use (&$shutdown) {
    error_log("Received shutdown signal");
    $shutdown = true;
});

while (true) {
  do_something();
  foreach (range(1, 5) as $num) {
    if ($shutdown) {
      error_log("Shutting down safely");
      exit(0);
    }
    sleep(1);
  }
}
```

## Do not detach

If you don't know what that is: never mind. If you do know: don't detach. To guarantee that we can monitor jobs correctly they need to run with-under the parent processes which started them. All detached processes will be killed.

## Overlapping jobs

Sometimes a cron job may be called multiple times and thus have multiple instances of the same job running. At best you should design your application that this is not happening or just within a controlled manner. Reasonable limits to control how many jobs of the same type can be started at once are applied.
